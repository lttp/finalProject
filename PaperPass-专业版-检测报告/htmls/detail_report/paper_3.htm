<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>PaperPass 最权威论文抄袭检测系统</title>
<style type="text/css">
<!--
user_icon {
color: #FFFFFF;
}
html
{
overflow-x:hidden;
overflow-y:auto;
}
body,td,th {
font-family: "微软雅黑";
font-size: 12px;
}
h1,h2,h3,h4,h5,h6 {
font-family: "宋体";
}
p{
margin-bottom:10px;
}
demo_padding {
line-height: 30px;
}
.zhengwen {
padding-right: 15px;
padding-left: 5px;
padding-bottom:100px;
font-size: 13px;
line-height: 20px;
color: #666666;
}
.zhengwencenter {
padding-right: 15px;
padding-left: 0px;
margin-bottom:10px;
font-size: 13px;
line-height: 20px;
color: #666666;
text-align:center
}
.neikuang {
background-color: #EBEBEB;
border: 1px solid #999999;
padding-right: 10px;
padding-left: 10px;
margin-top:10px;
margin-left:25px;
width:300px;
}
.shubu{
height: 20px;
width: 20px;
margin-left:25px;
background-color: #FFFFFF;
border: 1px solid #999999;
text-align: center;
vertical-align: middle;
display: block;
color: #666666;
}
a.red:link {color:#FF0000}
a.red:visited {color:#FF0000}
a.red:hover {color:#000000}
a.red:active {color:#000000}

a.orange:link {color:#FF6600}
a.orange:visited {color:#FF6600}
a.orange:hover {color:#000000}
a.orange:active {color:#000000}

a.dark:link {color:#666666}
a.dark:visited {color:#666666}
a.dark:hover {color:#000000}
a.dark:active {color:#000000}

a.pagelink:hover {color:#000000}
a.pagelink:active {color:#000000}

.green{color:#008000}
.gray{color:#666666}
.red{color:#FF0000}
.orange{color:#FF6600}
a{TEXT-DECORATION:none}

-->
</style>
</head>
<body>


<div class="zhengwen">
<div>
<span style="margin-left:25px"></span>
[
<a class="pagelink" href="paper_1.htm">首页</a>
<a class="pagelink" href="paper_2.htm">上一页</a>
<a class="pagelink" href="paper_4.htm">下一页</a>
<a class="pagelink" href="paper_6.htm">尾页</a>
页码：3/6页
]
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">56</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/170/170.htm' target='right' class='red' >4. 调度器返回下一个要爬取的URL给引擎，引擎将URL通过下载中间件(请求(request)方向)转发给下载器(Downloader)。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">57</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/171/171.htm' target='right' class='red' >5. 一旦页面下载完毕，下载器生成一个该页面的Response，并将其通过下载中间件(返回(response)方向)发送给引擎。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">58</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/172/172.htm' target='right' class='red' >6. 引擎从下载器中接收到Response并通过Spider中间件(输入方向)发送给Spider处理。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">59</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>7.</span><a href='../sentence_detail/174/174.htm' target='right' class='red' > Spider处理Response并返回爬取到的Item及(跟进的)新的Request给引擎。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">60</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>8. 引擎将(Spider返回的)爬取到的Item给Item Pipeline，将(Spider返回的)Request给调度器。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">61</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/176/176.htm' target='right' class='red' >9. (从第二步)重复直到调度器中没有更多地request，引擎关闭该网站。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">62</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>从其工作流程可以看出，该框架流程化的爬取过程可以让我们清晰的完成爬虫各个部分的工作，同时其允许用户自定义中间件让我们实现很多自定义的处理。</span><span class='green'>非常适合入门用户大量爬取数据。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">63</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>2.3 本章小结</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">64</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>本章中，我们分析了项目要使用的几个工具的优缺点以及为什么要使用。</span><span class='green'>包括平台框架Mediawiki，可视化工具库d3.js和爬虫框架scrapy。</span><span class='green'>其中Mediawiki框架因其为php开发对数据库的读取速度较慢，但是安装简单，扩展性好。</span><span class='green'>我们的平台中京津冀安全地图不会从数据库读取数据，数据格式全部为json格式存在文件系统中。</span><span class='green'>网络的分析也不会再平台中进行，平台用来展示结果。</span><span class='green'>故其数据库读取慢的缺点可以忽略。</span><span class='green'>D3.js对于数据的操作以及可视化的效果都非常优秀，同时入门简单，样例较多。</span><a href='../sentence_detail/187/187.htm' target='right' class='orange' >唯一的问题是，其v3版本基于svg进行可视化，对于大量的数据显示能力不如canvas。</a><span class='green'>我们的项目京津冀地图要用到d3.js，其数据量不大。</span><span class='green'>网络的计算并不会在平台上进行，故d3.js的能力约束不会对平台造成负担。</span><span class='green'>Scrapy爬虫框架需要进行一段时间的学习，其结构化的爬取流程以及可以定制的中间件非常方便，使得我们能够灵活的处理目标网站的反扒机制。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">65</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>第三章 数据获取</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">66</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.1 数据获取整体设计</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">67</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>京津冀安全大数据平台所需要的数据分为两个部分，</span><span class='green'>京津冀地理信息（即京津冀物理空间信息）以及京津冀地区在社交网络上的相关数据（即京津冀网络空间信息），</span><a href='../sentence_detail/195/195.htm' target='right' class='orange' >通过 scrapy框架进行爬取，整体爬取流程如图3.1所示。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">68</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>京津冀地理信息的数据用于构建京津冀安全地图，来自高德地图。</span><span class='green'>高德地图拥有京津冀详细的地理信息数据，且准确性可以保证。</span><span class='green'>我们需要用于构建京津冀安全地图的数据包括京津冀边界、京津冀的</span><span class='green'>路网数据、京津冀化工厂、加油站、事故多发路段坐标。</span><span class='green'>爬取后需要对数据进行清洗，首先去除重复信息，将道路名重复且坐标重复的信息删除；</span><span class='green'>然后需要对数据进行整理，去除无用数据，有些数据只包含道路名，但是并没有坐标；</span><a href='../sentence_detail/202/202.htm' target='right' class='orange' >然后统一格式，将数据格式转换为GeoJson格式，便于进行地图的绘制。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">69</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/203/203.htm' target='right' class='orange' >京津冀地区在社交网络上的相关数据用于构建京津冀舆论网络。</a><span class='green'>来自新浪微博。</span><a href='../sentence_detail/205/205.htm' target='right' class='orange' >新浪微博拥有大量的用户，话题传播非常迅速。</a><span class='green'>我们爬取的数据包括新浪微博关于京津冀以及京津冀安全方面的数据和主题词下用户的评论数据和用户的信息。</span><span class='green'>爬取后需要对数据进行清洗，首先合并相同主题微博，然后统一用户，将重复id的用户合并。</span><a href='../sentence_detail/208/208.htm' target='right' class='orange' >然后去除无用的数据，关键词缺失或者用户信息缺失的数据进行删除。</a><span class='green'>完成后将数据存储在本地。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">70</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/210/210.htm' target='right' class='orange' >图3.1 数据爬取顶层数据流图</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">71</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.2 地理信息获取</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">72</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>地理信息包括三部分，京津冀边界坐标、京津冀路网信息以及威胁京津冀安全的地理位置坐标。</span><a href='../sentence_detail/213/213.htm' target='right' class='orange' >这三部分构成了京津冀的安全地图。</a><span class='green'>三种数据的爬取方法各不相同。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">73</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.2.1 京津冀边界坐标获取</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">74</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>京津冀边界的坐标获取相对简单，可以直接使用高德地图提供的JavaScriptAPI中的绘制行政区划边界的功能。</span><span class='green'>以朝阳区为例，逻辑如图3.2所示。</span><a href='../sentence_detail/218/218.htm' target='right' class='orange' >首先连接地图，设置高德地图的中心以及缩放级别等基本信息。</a><span class='green'>完成后加载行政划区插件，实例</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">75</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><a href='../sentence_detail/220/220.htm' target='right' class='orange' >图3.2 行政区边界坐标获取流程</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">76</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>化插件，执行查询命令并获取朝阳区边界坐标，完成后将坐标保存在本地。</span><span class='green'>通过百度得到京津冀行政区名称列表，从列表中获取行政区名称，依次执行上述逻辑，得到所有的地图边界坐标。</span><span class='green'>因为是通过JavaScript在浏览器上爬取的坐标，没有遇到ip被ban的情况。</span><span class='green'>数据的完整性也有一定的保障。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">77</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>下面将爬取的行政区坐标与名称对整理成geoJson格式。</span><span class='green'>GeoJSON是一种对各种地理数据结构进行编码的格式[12]，它可以表示点、线、多边形等图形。</span><span class='green'>这种格式是标准的JavaScript绘制地图数据格式，d3.js对于地图的绘制使用的数据格式主要为GeoJson格式。</span><span class='green'>其标准格式如图3.3所示。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">78</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图3.3 GeoJson标准格式</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">79</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>京津冀边界数据属于多边型，故其geometry属性内的type属性为Polygon，同时其还有name属性，值为各个行政区的名字。</span><span class='green'>另外还要加上id属性，以区分各个行政区。</span><span class='green'>获得的行政区边界坐标写在geometry属性内的coordinate属性中。</span><a href='../sentence_detail/233/233.htm' target='right' class='orange' >至此，京津冀边界坐标格式化完成。</a>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">80</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>3.2.2 京津冀路网数据获取</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">81</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>京津冀路网数据的数据量较大，使用和京津冀边界数据获取相同方法的话，效率太低，可操作性太差。</span><span class='green'>故此处使用python的scrapy爬虫框架爬取京津冀路网数据。</span><span class='green'>首先获取道路名称，道路名称来自安居客网站。</span><span class='green'>然后通过获得的道路名称为keyword来访问高德地图的数据接口获得道路坐标。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">82</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>下面介绍道路名称获取方式。</span><span class='green'>道路名称的获得来源是图吧网站（http:</span><span class='green'>//www.mapbar.com）。</span><a href='../sentence_detail/242/242.htm' target='right' class='orange' >图吧公司全名北京图吧科技，是国内最专业的电子地图服务提供商。</a><span class='green'>道路来源url为http:</span><span class='green'>//poi.mapbar.com/tianjin/G70/，其面如图3.4所示。</span><span class='green'>其url中的tianjin即为天津。</span><span class='green'>同理，beijin即为北京。</span><span class='green'>因我们所需城市道路名仅限京津冀三地，故此处简单的复制粘贴即完成道路名获取。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">83</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图3.4 图吧天津道路名</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">84</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>下面介绍高德地图的数据接口。</span><span class='green'>高德地图的数据接口如图3.5所示。</span><span class='green'>其中传递的参数由 号连接，返回格式为json。</span><span class='green'>下面介绍几个重要参数，参数中city参数表示城市定位，keywords表示请求关键词，在这里添加道路名称，然后修改城市名称即可获得相应道路的信息。</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">85</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>图3.5 高德地图接口示例</span>
</p>
</div>

<div>
<p>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
<tr>
<td align="left" width="50"><div class="shubu">86</div></td>
<td>&nbsp;&nbsp;</td>
</tr>
</table>

<span style="margin-left:25px"></span><span class='green'>下面介绍scrapy爬取道路坐标的逻辑。</span><span class='green'>先介绍 scrapy的调度过程，如图3.6所示，调度器先从 spiders中获取 request，然后经过 downloaderMiddlewares发给 Downloader，</span><span class='green'>Downloader从网络中获得 response传给 spiders进行处理，完成后将 items发给 item pipeline进行进一步处理（保存或者丢弃）。</span>
</p>
</div>


<div>
<span style="margin-left:25px"></span>
[
<a class="pagelink" href="paper_1.htm">首页</a>
<a class="pagelink" href="paper_2.htm">上一页</a>
<a class="pagelink" href="paper_4.htm">下一页</a>
<a class="pagelink" href="paper_6.htm">尾页</a>
页码：3/6页
]
</div>

<br>
<div style="margin-left:8px">

<div style="text-align:center;background-color:#CA122C;margin-top:30px;overflow:hidden;">
<a href="http://www.paperpass.com/publish/index?from=ppreport_banner" target="_blank" style="display:block;"><img height="180" src="http://file.paperpass.com/images/fabiao.jpg"></a>
</div>

</div>
</div>


<div class="zhengwencenter">
<p>
检测报告由<a href="http://www.paperpass.com/" target="_blank">PaperPass</a>文献相似度检测系统生成
</p>
<p>
Copyright © 2007-2017 PaperPass
</p>
</div>
<div style="margin-bottom:400px"></div>
</body>
</html>
